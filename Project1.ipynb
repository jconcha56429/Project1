{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import petpy\n",
    "\n",
    "from datetime import datetime, date\n",
    "from petpy import Petfinder\n",
    "\n",
    "key = \"YOUR KEY HERE\"\n",
    "secret = \"YOUR KEY HERE\"\n",
    "\n",
    "datafile_16 = \"Resources/FY_2016_Dallas_Animal_Shelter_Data.csv\"\n",
    "datafile_17 = \"Resources/FY_2017_Dallas_Animal_Shelter_Data.csv\"\n",
    "datafile_18 = \"Resources/FY_2018_Dallas_Animal_Shelter_Data.csv\"\n",
    "datafile_19 = \"Resources/FY_2019_Dallas_Animal_Shelter_Data.csv\"\n",
    "datafile_20 = \"Resources/FY2020_Dallas_Animal_Shelter_Data.csv\"\n",
    "datafile_21 = \"Resources/FY2021_Dallas_Animal_Shelter_Data.csv\"\n",
    "\n",
    "df_2016 = pd.read_csv(datafile_16)\n",
    "df_2017 = pd.read_csv(datafile_17)\n",
    "df_2018 = pd.read_csv(datafile_18)\n",
    "df_2019 = pd.read_csv(datafile_19)\n",
    "df_2020 = pd.read_csv(datafile_20)\n",
    "df_2021 = pd.read_csv(datafile_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE ALL DALLAS FISCAL YEAR DATA INTO ONE DATAFRAME\n",
    "frames = [df_2016, df_2017, df_2018, df_2019, df_2020, df_2021]\n",
    "dallas_shelter_df = pd.concat(frames)\n",
    "dallas_shelter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF DUPLICATES (SAME ANIMAL ID AND MONTH ADMITTED TO SHELTER)\n",
    "dup_animals = dallas_shelter_df.loc[dallas_shelter_df.duplicated(subset = ['Animal Id', 'Month']), 'Animal Id'].unique()\n",
    "dup_animal_id = pd.DataFrame(dup_animals)\n",
    "dup_animal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dallas_shelter_clean = dallas_shelter_df[dallas_shelter_df['Animal Id'].isin(dup_animals)==False]\n",
    "dallas_shelter_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF UNNECESSARY COLUMNS AND GET RID OF ERRORS\n",
    "dallas_shelter_data_pre = dallas_shelter_clean.dropna(how='all', subset=['Animal Breed'])\n",
    "dallas_shelter_data = dallas_shelter_data_pre.drop(columns=['Source Id', 'Activity Sequence', 'Receipt Number', 'Census Tract', 'Intake Time', 'Outcome Time','Tag Type', 'Activity Number', 'Service Request Number', 'Unnamed: 16','Unnamed: 27'])\n",
    "dallas_shelter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK FORMATTING OF COLUMNS (DTYPES)\n",
    "dallas_shelter_data['Intake Date'] = pd.to_datetime(dallas_shelter_data['Intake Date'])\n",
    "dallas_shelter_data['Outcome Date'] = pd.to_datetime(dallas_shelter_data['Outcome Date'])\n",
    "dallas_shelter_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CLEAN MERGED DALLAS DATA TO CSV\n",
    "dallas_shelter_data.to_csv(\"Resources/DallasData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a call to the Petfinder API\n",
    "pf = Petfinder(key=key, secret=secret)\n",
    "\n",
    "try:\n",
    "    # Calls API and puts info in a dictionary\n",
    "    animals = pf.animals()  \n",
    "\n",
    "    # Extracting data on specific animals with animal_ids\n",
    "    animal_ids = []\n",
    "    for i in animals['animals'][0:3]:\n",
    "        animal_ids.append(i['id'])\n",
    "    \n",
    "    animal_data = pf.animals(animal_id=animal_ids)\n",
    "\n",
    "    # Returning a pandas DataFrame of the first 10,000 animal results\n",
    "    animals = pf.animals(results_per_page=100, pages=100, return_df=True) # Max pages is 100\n",
    "                                                                          # Max results per page is 100\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Get rid of columns we don't need\n",
    "animals = animals[['id', 'organization_id', 'type','species', 'age', 'gender', 'size',\n",
    "                    'coat', 'tags', 'description', 'organization_animal_id', 'status',\n",
    "                    'status_changed_at', 'published_at', 'breeds.primary', 'breeds.secondary', \n",
    "                    'breeds.mixed', 'breeds.unknown', 'colors.primary', 'colors.secondary', \n",
    "                    'colors.tertiary', 'contact.address.city', 'contact.address.state', \n",
    "                    'contact.address.country', 'animal_id', \n",
    "                    'animal_type', 'organization_id']]\n",
    "\n",
    "# Creates csv file from DataFrame\n",
    "animals.to_csv(\"Resources/Animals.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
